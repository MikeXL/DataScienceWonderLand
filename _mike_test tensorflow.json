{"paragraphs":[{"text":"%livykeraspy36.pyspark\nimport tensorflow as tf\nprint(tf.__version__)","user":"t844523","dateUpdated":"2018-12-21T14:26:28-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"1.4.1\n/python_env/keras_py3.6_env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n/python_env/keras_py3.6_env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n/python_env/keras_py3.6_env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n/python_env/keras_py3.6_env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)"},{"type":"HTML","data":"<hr/>Spark Application Id: application_1545305032014_7599<br/>Spark WebUI: <a href=\"http://qcr-hadoop-m005.oss.ads:8088/proxy/application_1545305032014_7599/\">http://qcr-hadoop-m005.oss.ads:8088/proxy/application_1545305032014_7599/</a>"}]},"apps":[],"jobName":"paragraph_1526008667249_-1589803956","id":"20180510-231747_916176353","dateCreated":"2018-05-10T23:17:47-0400","dateStarted":"2018-12-21T14:26:28-0500","dateFinished":"2018-12-21T14:27:03-0500","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3456"},{"text":"%md\n$$V(x_{0}) = max \\sum_{t=0}^{\\infty}\\beta^tF(x_{t}, a_{t})$$","user":"t844523","dateUpdated":"2018-12-21T14:27:38-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545420453190_-968518384","id":"20181221-142733_823878598","dateCreated":"2018-12-21T14:27:33-0500","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3829","dateFinished":"2018-12-21T14:27:38-0500","dateStarted":"2018-12-21T14:27:38-0500","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>$$V(x_{0}) = max \\sum_{t=0}^{\\infty}\\beta^tF(x_{t}, a_{t})$$</p>\n</div>"}]}},{"text":"%livykeraspy36.pyspark\n'''\nA linear regression learning algorithm example using TensorFlow library.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n'''\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy\nimport matplotlib.pyplot as plt\nrng = numpy.random\n\n# Parameters\nlearning_rate = 0.01\ntraining_epochs = 1000\ndisplay_step = 50\n\n# Training Data\ntrain_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\ntrain_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\nn_samples = train_X.shape[0]\n\n# tf Graph Input\nX = tf.placeholder(\"float\")\nY = tf.placeholder(\"float\")\n\n# Set model weights\nW = tf.Variable(rng.randn(), name=\"weight\")\nb = tf.Variable(rng.randn(), name=\"bias\")\n\n# Construct a linear model\npred = tf.add(tf.multiply(X, W), b)\n\n# Mean squared error\ncost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n# Gradient descent\n#  Note, minimize() knows to modify W and b because Variable objects are trainable=True by default\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Fit all training data\n    for epoch in range(training_epochs):\n        for (x, y) in zip(train_X, train_Y):\n            sess.run(optimizer, feed_dict={X: x, Y: y})\n\n        # Display logs per epoch step\n        if (epoch+1) % display_step == 0:\n            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n                \"W=\", sess.run(W), \"b=\", sess.run(b))\n\n    print(\"Optimization Finished!\")\n    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n\n    # Graphic display\n    # plt.plot(train_X, train_Y, 'ro', label='Original data')\n    # plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n    # plt.legend()\n    # plt.show()\n\n    # Testing example, as requested (Issue #2)\n    test_X = numpy.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1])\n    test_Y = numpy.asarray([1.84, 2.273, 3.2, 2.831, 2.92, 3.24, 1.35, 1.03])\n\n    print(\"Testing... (Mean square loss Comparison)\")\n    testing_cost = sess.run(\n        tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * test_X.shape[0]),\n        feed_dict={X: test_X, Y: test_Y})  # same function as cost above\n    print(\"Testing cost=\", testing_cost)\n    print(\"Absolute mean square loss difference:\", abs(\n        training_cost - testing_cost))\n\n    # plt.plot(test_X, test_Y, 'bo', label='Testing data')\n    # plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n    # plt.legend()\n    # plt.show()","user":"t844523","dateUpdated":"2018-09-19T13:37:57-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Epoch: 0050 cost= 0.125019029 W= 0.37221438 b= -0.08065877\nEpoch: 0100 cost= 0.119465731 W= 0.36492157 b= -0.02819457\nEpoch: 0150 cost= 0.114553966 W= 0.35806242 b= 0.021149352\nEpoch: 0200 cost= 0.110209681 W= 0.35161126 b= 0.0675585\nEpoch: 0250 cost= 0.106367290 W= 0.34554377 b= 0.1112075\nEpoch: 0300 cost= 0.102968849 W= 0.3398373 b= 0.1522604\nEpoch: 0350 cost= 0.099963129 W= 0.33447003 b= 0.19087183\nEpoch: 0400 cost= 0.097304754 W= 0.32942194 b= 0.22718687\nEpoch: 0450 cost= 0.094953619 W= 0.32467422 b= 0.2613418\nEpoch: 0500 cost= 0.092874236 W= 0.32020873 b= 0.2934656\nEpoch: 0550 cost= 0.091035172 W= 0.316009 b= 0.32367912\nEpoch: 0600 cost= 0.089408726 W= 0.31205893 b= 0.35209534\nEpoch: 0650 cost= 0.087970294 W= 0.3083437 b= 0.37882218\nEpoch: 0700 cost= 0.086698182 W= 0.30484954 b= 0.40395948\nEpoch: 0750 cost= 0.085573256 W= 0.30156317 b= 0.4276006\nEpoch: 0800 cost= 0.084578373 W= 0.29847232 b= 0.44983634\nEpoch: 0850 cost= 0.083698571 W= 0.29556522 b= 0.47074983\nEpoch: 0900 cost= 0.082920574 W= 0.292831 b= 0.49041927\nEpoch: 0950 cost= 0.082232580 W= 0.29025957 b= 0.50891864\nEpoch: 1000 cost= 0.081624277 W= 0.28784102 b= 0.52631694\nOptimization Finished!\nTraining cost= 0.08162428 W= 0.28784102 b= 0.52631694 \n\nTesting... (Mean square loss Comparison)\nTesting cost= 0.07668329\nAbsolute mean square loss difference: 0.0049409866"},{"type":"HTML","data":"<hr/>Spark Application Id: application_1536430926361_66726<br/>Spark WebUI: <a href=\"http://qcr-hadoop-m003.oss.ads:8088/proxy/application_1536430926361_66726/\">http://qcr-hadoop-m003.oss.ads:8088/proxy/application_1536430926361_66726/</a>"}]},"apps":[],"jobName":"paragraph_1537378233518_1691292219","id":"20180919-133033_1565474402","dateCreated":"2018-09-19T13:30:33-0400","dateStarted":"2018-09-19T13:37:45-0400","dateFinished":"2018-09-19T13:37:53-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3457"},{"text":"%livykeraspy36.pyspark\n","user":"t844523","dateUpdated":"2018-09-19T13:36:01-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1537378561794_-1069790126","id":"20180919-133601_800962146","dateCreated":"2018-09-19T13:36:01-0400","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:3458"}],"name":"/mike/test tensorflow","id":"2DF3XVSQJ","angularObjects":{"2D619KHUP:shared_process":[],"2DDQT9REW::2DF3XVSQJ":[],"2D5PHGT1R:shared_process":[],"2D3YBZG7J:t844523:":[],"2D3RV8ZDD:shared_process":[],"2DE4SQNJW::2DF3XVSQJ":[],"2D5TTXG6N:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2D6JZ867W:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}